{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "FONT_SIZE = 12\n",
    "AXES_SIZE = FONT_SIZE * 1.5\n",
    "TICK_SIZE = FONT_SIZE * 1.25\n",
    "LEGEND_SIZE = FONT_SIZE\n",
    "\n",
    "my_rcParams = {\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"lines.linewidth\": 5,\n",
    "    \"font.size\": FONT_SIZE,\n",
    "    \"font.family\": \"Helvetica\",\n",
    "    \"axes.titlesize\": AXES_SIZE,\n",
    "    \"axes.labelsize\": AXES_SIZE,\n",
    "    \"xtick.labelsize\": TICK_SIZE,\n",
    "    \"ytick.labelsize\": TICK_SIZE,\n",
    "    \"legend.fontsize\": LEGEND_SIZE,\n",
    "    \"xtick.major.pad\": FONT_SIZE / 2,\n",
    "    \"ytick.major.pad\": FONT_SIZE / 2,\n",
    "}\n",
    "\n",
    "for k, v in my_rcParams.items():\n",
    "    mpl.rcParams[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_name = [\"WW\", \"SR\"]\n",
    "variation_colors = [\"#30BCED\", \"#A6FFA1\"]\n",
    "vc_map = dict(zip(variation_name, variation_colors))\n",
    "\n",
    "CLICK_RATE = np.array([0.1, 0.15])\n",
    "visitors_per_day= np.array([500])\n",
    "assignment_p = np.ones_like(CLICK_RATE) / len(CLICK_RATE)\n",
    "\n",
    "# Sample data \n",
    "def sample_clicks(visitors, click_rate, assignment_p):\n",
    "    assigned_variations = random.multinomial(visitors, pvals=assignment_p)\n",
    "    observed_clicks = [random.binomial(n_assigned, click_rate[variation]) for variation, n_assigned in enumerate(assigned_variations)] \n",
    "    return assigned_variations, observed_clicks\n",
    "\n",
    "def make_data(visitors_per_day, click_rate, assignment_p):\n",
    "    dfs = []\n",
    "    for day, visits in enumerate(visitors_per_day):\n",
    "        impressions, clicks = sample_clicks(visits, click_rate, assignment_p)\n",
    "        df_today = pd.DataFrame({\n",
    "            \"variation\": variation_name,\n",
    "            \"impressions\": impressions,\n",
    "            \"clicks\": clicks,\n",
    "            \"day\": day\n",
    "            })\n",
    "        dfs.append(df_today)\n",
    "    return pd.concat(dfs)\n",
    "    \n",
    "data = make_data(visitors_per_day, CLICK_RATE, assignment_p)\n",
    "data.to_csv(\"../ad_clicks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior intervals of click rate through time\n",
    "from scipy.stats import beta \n",
    "\n",
    "posterior_samples = 5_000\n",
    "\n",
    "posterior_click_rates_dict = {}\n",
    "\n",
    "# Sum by variation\n",
    "data_agg = data.groupby(\"variation\").agg({\"clicks\": \"sum\", \"impressions\": \"sum\"}).reset_index()\n",
    "def _compute_posterior(clicks, impressions, a=1, b=1):\n",
    "    return beta(a + clicks, b + impressions - clicks)\n",
    "\n",
    "priors = {v: _compute_posterior(np.zeros_like(g[\"clicks\"]), np.zeros_like(g[\"impressions\"])) for v, g in data_agg.groupby(\"variation\")}\n",
    "posteriors = {v: _compute_posterior(g[\"clicks\"], g[\"impressions\"]) for v, g in data_agg.groupby(\"variation\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10., 5.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=1, nrows=len(variation_name))\n",
    "for i, v in enumerate(variation_name):\n",
    "    ax = fig.add_subplot(spec[i])\n",
    "    ax.hist(priors[v].rvs(size=posterior_samples), color=vc_map[v], ec=\"k\", alpha=0.2, label=f\"Prior ({v})\", bins=20,)\n",
    "    ax.hist(posteriors[v].rvs(size=posterior_samples), color=vc_map[v], ec=\"k\", label=f\"Posterior ({v})\", bins=20)\n",
    "    ax.set_xlabel(\"Click through rate\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.legend()\n",
    "\n",
    "fig.savefig(\"../figures/prior-posterior.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10., 6), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=1, nrows=3)\n",
    "\n",
    "alphasbetas = [1, 25, 500]\n",
    "alphasbetas_colors = [\"lightblue\", \"slateblue\", \"darkblue\"]\n",
    "\n",
    "def get_prior_post(alpha, beta):\n",
    "    prior = {v: _compute_posterior(np.zeros_like(g[\"clicks\"]), np.zeros_like(g[\"impressions\"]), a=alpha, b=beta) for v, g in data_agg.groupby(\"variation\")}\n",
    "    posteriors = {v: _compute_posterior(g[\"clicks\"], g[\"impressions\"], a=alpha, b=beta) for v, g in data_agg.groupby(\"variation\")}\n",
    "    return prior, posteriors\n",
    "\n",
    "for i, ab in enumerate(alphasbetas):\n",
    "    ax = fig.add_subplot(spec[i])\n",
    "    priors_, posteriors_ = get_prior_post(alpha=ab, beta=ab)\n",
    "    ax.hist(priors_[v].rvs(size=posterior_samples), \n",
    "            alpha=0.2, color=alphasbetas_colors[i], ec=\"k\", label=r\"Prior($\\alpha=\\beta=$\" + str(ab) + \")\", bins=20)\n",
    "    ax.hist(posteriors_[v].rvs(size=posterior_samples),\n",
    "             color=alphasbetas_colors[i], ec=\"k\", label=\"Posterior\", bins=20)\n",
    "    ax.axvline(x=CLICK_RATE[0], color=\"k\", label=\"True value\")\n",
    "    ax.set_xlabel(\"Click through rate\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_xlim((0,1))\n",
    "    ax.legend()\n",
    "\n",
    "fig.savefig(\"../figures/changing-prior-posterior.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posteriors\n",
    "fig = plt.figure(figsize=(10., 6.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=1, nrows=2)\n",
    "ax = fig.add_subplot(spec[0])\n",
    "ax_greater_than = fig.add_subplot(spec[1])\n",
    "for v, dist in posteriors.items():\n",
    "    ax.hist(dist.rvs(size=posterior_samples),  color=vc_map[v], ec=\"k\", alpha=0.5, label=v, bins=20, density=True)\n",
    "ax.set_xlabel(\"Click through rate\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.legend()\n",
    "\n",
    "# Plot differences\n",
    "def compute_lift(posteriors, p1, p0, size=1000):\n",
    "    if p1 == p0:\n",
    "        return np.zeros(size)\n",
    "    else:\n",
    "        return posteriors[p1].rvs(size=size) - posteriors[p0].rvs(size=size) \n",
    "\n",
    "lift = compute_lift(posteriors, variation_name[-1], variation_name[0], size=posterior_samples)\n",
    "ax_greater_than.hist(lift, \n",
    "                     color=\"purple\",\n",
    "                     ec=\"k\",\n",
    "                     alpha=0.5,\n",
    "                     label=f\"Lift of {variation_name[-1]} over {variation_name[0]}\",\n",
    "                     bins=20,\n",
    "                     density=True)\n",
    "ax_greater_than.axvline(x=0.0, color=\"k\", linestyle=\"--\", linewidth=2.5)\n",
    "ax_greater_than.set_xlabel(\"Lift\")\n",
    "ax_greater_than.set_ylabel(\"Density\")\n",
    "ax_greater_than.legend()\n",
    "\n",
    "fig.savefig(\"../figures/posterior-lift.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we make a conclusion with this data?\n",
    "def compute_expected_loss(posteriors, size=1000):\n",
    "    # Basically want to compute lift for all things and take maximum\n",
    "    loss = {}\n",
    "    expected_loss = {}\n",
    "    for p in posteriors.keys():\n",
    "        lifts = np.array([compute_lift(posteriors, p, ps) for ps in posteriors.keys()])\n",
    "        loss[p] = (-lifts).max(axis=0)\n",
    "        expected_loss[p] = loss[p].mean()\n",
    "    return loss, expected_loss\n",
    "\n",
    "def make_decision(thres_caring, expected_losses):\n",
    "    below_thres = {k: v < thres_caring for k,v in expected_losses.items()}\n",
    "    for k, v in below_thres.items():\n",
    "        if v:\n",
    "            print(f\"{k} is acceptable\")\n",
    "\n",
    "thres_caring = 0.02 # \n",
    "make_decision(thres_caring, expected_losses)# This can work for an arbritary loss function, say if there is a cost for swtichign\n",
    "\n",
    "\n",
    "#expected_losses = compute_expected_loss(posteriors)\n",
    "#for p, expected_loss in expected_losses.items():\n",
    "#    ax_greater_than.axvline(x=expected_loss, color=vc_map[p])\n",
    "\n",
    "\n",
    "#ax_greater_than.axvline(x=thres_caring, color=\"k\", linewidth=2.5, label=\"Threshold of caring\")\n",
    "#ax_greater_than.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10., 6.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=1, nrows=2)\n",
    "\n",
    "loss, expected_loss= compute_expected_loss(posteriors)\n",
    "for i, v in enumerate(variation_name):\n",
    "    ax = fig.add_subplot(spec[i], sharex= None if i==0 else ax)\n",
    "    ax.hist(loss[v], color=vc_map[v], ec=\"k\", alpha=0.5, label=v, bins=20)\n",
    "    ax.axvline(x=expected_loss[v], color=\"k\", label= \"Expected loss\")\n",
    "    ax.set_xlabel(\"Loss\")\n",
    "    ax.legend()\n",
    "\n",
    "fig.savefig(\"../figures/posterior-loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_caring = 0.01 # \n",
    "\n",
    "fig = plt.figure(figsize=(6, 4.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=1, nrows=1)\n",
    "ax = fig.add_subplot(spec[0])\n",
    "\n",
    "loss, expected_loss= compute_expected_loss(posteriors)\n",
    "\n",
    "ax.axhline(y=thres_caring, color=\"k\", linewidth=5.5, label=\"Threshold of caring\")\n",
    "ax.bar(expected_losses.keys(), expected_losses.values(), color=[vc_map[v] for v in expected_losses.keys()], ec=\"k\")\n",
    "ax.set_ylabel(\"Expected Loss\")\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig(\"../figures/expected-loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior intervals of click rate through time\n",
    "from scipy.stats import beta \n",
    "\n",
    "posterior_samples = 5000\n",
    "\n",
    "fig = plt.figure(figsize=(12., 6.), constrained_layout=True)\n",
    "spec = fig.add_gridspec(ncols=2, nrows=2, width_ratios=[1.0, 0.5])\n",
    "ax = fig.add_subplot(spec[0, 0])\n",
    "ax_greater_than = fig.add_subplot(spec[1, 0])\n",
    "ax_expected_loss = fig.add_subplot(spec[:, 1])\n",
    "posterior_click_rates_dict = {}\n",
    "\n",
    "# Sum by variation\n",
    "data_agg = data.groupby(\"variation\").agg({\"clicks\": \"sum\", \"impressions\": \"sum\"}).reset_index()\n",
    "def _compute_posterior(clicks, impressions, a=1, b=1):\n",
    "    return beta(a + clicks, b + impressions - clicks)\n",
    "\n",
    "posteriors = {v: _compute_posterior(g[\"clicks\"], g[\"impressions\"]) for v, g in data_agg.groupby(\"variation\")}\n",
    "\n",
    "# Plot posteriors\n",
    "for v, dist in posteriors.items():\n",
    "    ax.hist(dist.rvs(size=posterior_samples),  color=vc_map[v], ec=\"k\", alpha=0.5, label=v, bins=20, density=True)\n",
    "ax.set_xlabel(\"Click through rate\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.legend()\n",
    "\n",
    "# Plot differences\n",
    "def compute_value(posteriors, p1, p0, size=1000):\n",
    "    if p1 == p0:\n",
    "        return np.zeros(size)\n",
    "    else:\n",
    "        return posteriors[p1].rvs(size=size) - posteriors[p0].rvs(size=size)\n",
    "\n",
    "# Compute values\n",
    "relative_to = variation_name[0]\n",
    "for variation in variation_name[1:]:\n",
    "    value = compute_value(posteriors, variation, relative_to, size=posterior_samples)\n",
    "    ax_greater_than.hist(value, ec=\"k\", color=vc_map[variation], alpha=0.5, label=f\"Value of {variation} over {relative_to}\", bins=20, density=True)\n",
    "\n",
    "ax_greater_than.axvline(x=0.0, color=\"k\", linestyle=\"--\", linewidth=2.5)\n",
    "ax_greater_than.set_xlabel(\"Lift\")\n",
    "ax_greater_than.set_ylabel(\"Density\")\n",
    "\n",
    "# Making a decision with this data\n",
    "def compute_expected_loss(posteriors, size=1000):\n",
    "    # Basically want to compute lift for all things and take maximum\n",
    "    expected_loss = {}\n",
    "    def compute_loss(posteriors, p1, p0, size=size):\n",
    "        relative_lift = compute_value(posteriors, p1, p0)\n",
    "        loss = (-relative_lift)\n",
    "        return loss \n",
    "    \n",
    "    for p in posteriors.keys():\n",
    "        # Consider values if we try alternatives to p when p is true\n",
    "        loss = np.array([compute_loss(posteriors, p, alt) for alt in posteriors.keys()])\n",
    "        expected_loss[p] = loss.max(axis=0).mean() # Loss occurs when alternatives are better (max_value > 0)\n",
    "    return expected_loss\n",
    "\n",
    "\n",
    "def make_decision(thres_caring, expected_losses):\n",
    "    below_thres = {k: v < thres_caring for k,v in expected_losses.items()}\n",
    "    for k, v in below_thres.items():\n",
    "        if v:\n",
    "            print(f\"{k} is acceptable\")\n",
    "\n",
    "thres_caring = 0.01 # \n",
    "make_decision(thres_caring, expected_losses)# This can work for an arbritary loss function, say if there is a cost for swtichign\n",
    "ax_greater_than.legend()\n",
    "\n",
    "ax_expected_loss.axhline(y=thres_caring, color=\"k\", linewidth=5.5, label=\"Threshold of caring\")\n",
    "expected_losses = compute_expected_loss(posteriors)\n",
    "ax_expected_loss.bar(expected_losses.keys(), expected_losses.values(), color=[vc_map[v] for v in expected_losses.keys()], label=f\"Choosing {p}\", ec=\"k\")\n",
    "ax_expected_loss.set_ylabel(\"Expected Loss\")\n",
    "print(expected_losses)\n",
    "\n",
    "# If you use relative lift, you're losing by going A, so loss is A/B - 1, but gain by choosing would be B/A - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat with weighted example for binary decision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want figures that will allow me to look at sample size needed given power, alpha as a function of effect size?\n",
    "\n",
    "The follow up here would be then leaveraging A/B test results for some other outcome.\n",
    "\n",
    "Which will lead to actual benefit.\n",
    "\n",
    "Say we have paid users verus unpaid users. How do we maximize profit of our choice ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRateExperiment:\n",
    "    def __init__(self, counts, totals, group, a_prior=1, b_prior=1, size=1_000):\n",
    "        self.counts, self.totals = counts, totals\n",
    "        self.group = group\n",
    "        self.a_prior = a_prior\n",
    "        self.b_prior = b_prior\n",
    "\n",
    "        self.size = size\n",
    "        self.posterior = {}\n",
    "        self.samples = {}\n",
    "        self.expected_losses = {}\n",
    "\n",
    "    def _compute_posterior(self, data):\n",
    "        for name, group in data.groupby(self.group):\n",
    "            self.posterior[name] = beta(self.a_prior + group[self.counts], self.b_prior + group[self.totals] - group[self.counts])\n",
    "    \n",
    "    def _sample_posterior(self):\n",
    "        for name, post in self.posterior.items():\n",
    "            self.samples[name] = post.rvs(self.size)\n",
    "\n",
    "    def _compute_lift(self, current, alternative):\n",
    "        return self.samples[alternative] - self.samples[current]\n",
    "\n",
    "    def decide(self, thres_caring=0.01):\n",
    "        # Compute expected loss\n",
    "        for current, post in self.posterior.items():\n",
    "            lifts = np.asarray([self._compute_lift(current, alt) for alt in self.posterior.keys()]) \n",
    "            self.expected_losses[current] = -(-lifts).min(axis=0).mean()\n",
    "        \n",
    "        # Check to see which alternatives if any meet threshold of caring\n",
    "        threshold_met = False\n",
    "        for alt, expected_loss in self.expected_losses.items():\n",
    "            if expected_loss < thres_caring:\n",
    "                print(f\"{alt} is acceptable\")\n",
    "                threshold_met = True\n",
    "        if threshold_met:\n",
    "            self.decision = min(expected_losses, key=expected_losses.get)\n",
    "            print(f\"We choose {self.decision}.\")\n",
    "        else:\n",
    "            print(\"No alternatives met the threshold of caring.\")\n",
    "    \n",
    "    def run_test(self, data, thres_caring=None):\n",
    "        # Fit individual count models\n",
    "        self._compute_posterior(data)\n",
    "        self._sample_posterior()\n",
    "\n",
    "        # Make decision\n",
    "        if thres_caring is not None:\n",
    "            self.decide(thres_caring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SimpleRateExperiment(counts=\"clicks\", totals=\"impressions\", group=\"variation\")\n",
    "experiment.run_test(data_agg, thres_caring=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
